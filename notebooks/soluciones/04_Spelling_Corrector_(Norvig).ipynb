{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Nfi3eeZR40"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "En el campo del NLP, existen multitud de causas por las cuales pueden aparecer errores en campos de texto. Algunas muy comunes pueden ser:\n",
        "- Typos al escribir\n",
        "- Errores de reconocimiento de un ASR\n",
        "- Errores al transcribir imágenes a texto (OCR)\n",
        "\n",
        "Aunque hoy en día existen modelos complejos basados en Deep Learning (como pueden ser los seq2seq), existen otros mucho menos complejos basados en determinar la similitud (o diferencia) entre strings en cuanto al número de cambios lexico-gráficos necesarios para transformar un string en otro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2nEfNdpZR43"
      },
      "source": [
        "# Distancia de Edición\n",
        "\n",
        "La distancia de edición es un método para calcular la similitud entre cadenas de caracteres. Aunque veremos más ejemplos en el notebook de **Matching** y sucesivos, se introduce aquí para presentar un algoritmo de corrección ortográfica.\n",
        "\n",
        "Dicha distancia tiene en cuenta el **número mínimo de operaciones** requeridas para transformar una cadena de caracteres en otra. También se utiliza en bioinformática para cuantificar la similitud entre cadenas de ADN.\n",
        "\n",
        "En función de las operaciones que se permitan, existen **distintos tipos de Distancia de Edición**:\n",
        "\n",
        "|                Distancia               \t| Inserción \t| Eliminación \t| Sustitución \t| Transposición \t|\n",
        "|:--------------------------------------:\t|:---------:\t|:-----------:\t|:-----------:\t|:-------------:\t|\n",
        "|               Levenshtein              \t|     Y     \t|      Y      \t|      Y      \t|       -       \t|\n",
        "| Subsecuencia Común <br>más Larga (LCS) \t|     Y     \t|      Y      \t|      -      \t|       -       \t|\n",
        "|                Hamming \\*               \t|     -     \t|      -      \t|      Y      \t|       -       \t|\n",
        "|         Damerau-Levenshtein \\**         \t|     Y     \t|      Y      \t|      -      \t|       Y       \t|\n",
        "|                  Jaro                  \t|     -     \t|      -      \t|      -      \t|       Y       \t|\n",
        "\n",
        "- \\* _Solo sirve para strings de igual longitud_\n",
        "- \\** _Transposición de dos caracteres adyacentes_\n",
        "\n",
        "Además del número de operaciones, también debe definirse la penalización por cada operación. Una posibilidad es la de que cada operación suponga sumar +1 a la distancia entre dos strings.\n",
        "\n",
        "> d('_cena_', '_coma_') = 2\n",
        "\n",
        "Si se define un coste positivo se cumple lo siguiente:\n",
        "- d(a, b) = 0, solo si a=b\n",
        "- d(a, b) > 0, si a$\\neq$b\n",
        "- d(a, b) = d(b, a)\n",
        "\n",
        "Hay que tener en cuenta que una edición no tiene porqué resultar en una palabra real.\n",
        "\n",
        "## Distancia de Levenshtein\n",
        "\n",
        "Operaciones permitidas: inserción, eliminación y sustitución.\n",
        "\n",
        "<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/4520f5376b54613a5b0e6c6db46083989f901821>\n",
        "\n",
        "En este artículo lo explican de maravilla: [link](https://medium.com/@ethannam/understanding-the-levenshtein-distance-equation-for-beginners-c4285a5604f0)\n",
        "\n",
        "<img src=https://miro.medium.com/max/1108/1*bEWdxv_FoTQurG9fyS3nSA.jpeg width=300px>\n",
        "\n",
        "## Utilidad\n",
        "\n",
        "Encontrar palabras _cercanas_ entre sí en cuanto a su similitud lexico-gráfica permite, entre otras cosas, corregir pequeños errores o incorrecciones en un texto.\n",
        "\n",
        "Veremos un algoritmo sencillo de _Spelling Correction_ desarrollado por  Peter Norvig. [Link](https://norvig.com/spell-correct.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unzip\n",
        "!pip install -r requirements.txt\n",
        "!pip install utils.py"
      ],
      "metadata": {
        "id": "G9eNymIqF2pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip corpusCine.zip"
      ],
      "metadata": {
        "id": "8Egqpyq-F5K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlJ-cL1LZR44"
      },
      "source": [
        "# Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vviqNpYOZR45"
      },
      "outputs": [],
      "source": [
        "\n",
        "from utils import load_cinema_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfHeJHEVZR46"
      },
      "outputs": [],
      "source": [
        "# Path al directorio donde tenemos los datasets con las reviews\n",
        "datasets_path = './'\n",
        "corpus_cine_folder = 'corpusCine'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAItlDiIZR46"
      },
      "outputs": [],
      "source": [
        "reviews_dict = load_cinema_reviews(datasets_path, corpus_cine_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "02FPgm_OZR46"
      },
      "outputs": [],
      "source": [
        "reviews_list = list()\n",
        "\n",
        "for key, item in reviews_dict.items():\n",
        "    reviews_list.append(item.get('review_text'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_list[0]"
      ],
      "metadata": {
        "id": "G0ZnyO4cYtVf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "e23e51a7-2351-4758-a720-0d7df63da9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cada vez me gusta menos el cine de masas. Las peliculas que ven todo el mundo me parecen cada vez mas coñazo y mas insufribles. No se porqué pero siempre el prota es tonto del culo y tiene suerte, y al final de la peli, cuando ha logrado vencer al mal, se convierte en listo, y las chorradas que hacia al comienzo de la pelicula se esfuman como por arte de magia. Se vuelve maduro e inteligente.Esta peli de Spielberg es mas de lo mismo, huir y huir y que no le den ni un solo tiro. Además el cabron ha metido a un par de actores que es como para echarles de comer aparte. La niña, una vieja metida en el cuerpo de una niña, porque solo hay que verle hablar (en version original claro) para darse cuenta que estamos ante uno de los grandes freaks del cine. Se creeran que hace gracia la nena cuando habla igual que su puta madre, pero a mi me causa pavor. Ver a una cria que habla como una persona madura es algo horroroso. Los niños son niños y verlos fuera de su rol asusta.Luego esta el hijo adolescente que tiene el Cruise. Otro subnormal que es para darle de bofetadas hasta que se te vea el hueso a la mano. Fiel reflejo de lo que se denomina manipulacion militar, el chico quiere matar a los bichos sin ningun arma, hale, a lo loco y sin pensar, venga, a saco.Que quereis que os diga, pero a mi eso me parece fanatismo y locura. Que alguien quiera ir a luchar sin medios es ir a una muerte segura, por eso me jode sobremanera que al final de la pelicula aparezca el mongo este y sus abuelos y toda la familia. Se salva todo dios, y encima la vieja aparece en traje de los domingos y toda maquillada.¿Pero que sinsorgada es esta? Solo falta que Cruise vuelva con su exmujer y que el mundo sea mucho mejor. Tranquilos, os cuento el final de la peli pero no pasa nada, todas las pelis acaban de igual manera, y decir eso no resta misterio al bodrio este. Yo no se de que va Spielberg, pero a este paso se va a convertir tan solo en un director que es bueno haciendo efectos especiales, porque lo que es contando historias?¿No os disteis cuenta de que los norteamericanos no saben guardar la compostura? Que todo lo dicen gritando. En momentos dificiles lo mas sensato es tranquilizarse y no discutir por chorradas, y en toda la puta peli no paran de gritar y pegarse entre ellos.Me hace gracia como al comienzo de la peli, cuando el suelo empieza a resquebrajarse, la gente se queda ahí a mirar que pasa. Joder, no se ellos, pero yo ya estaria corriendo como una puta desde hace tiempo, e escondiéndome. Si veo que un bicho esta lanzando rayos y machacando a to dios, me escondo.En fin, que para que seguir hablando de esta mierda, si lo que querian ya lo han conseguido, que es que pagasemos la entrada, por eso creo que va a ir al cine su prima, a partir de ahora me lo bajare todo de internet, que por lo que se ve, la calidad de las pelis es aceptable, y puedo pasarla palante. Hoy en dia no tener un mando con el forward en la mano es morir.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oukrK2GWZR47"
      },
      "source": [
        "# Algoritmo de Peter Norvig para Spell Checking\n",
        "\n",
        "Peter Norvig, ex-director de Calidad de búsqueda en Google, escribió este _simple_, pero eficiente, algoritmo para corregir errores ortográficos. Según comenta lo escribió en un vuelo transcontinental para explicar el funcionamiento de un corrector ortográfico _funcional_ de una manera _sencilla_\n",
        "\n",
        "[Link](https://norvig.com/spell-correct.html)\n",
        "\n",
        "<img src=https://upload.wikimedia.org/wikipedia/commons/b/b8/Peter_Norvig_in_2019.jpg width=300px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuoA5u6gZR48"
      },
      "source": [
        "## ¿Cómo funciona?\n",
        "\n",
        "El objetivo principal es, dada una palabra _w_, un conjunto de candidatos que pudieran ser susceptibles de ser su corrección. A priori no podemos conocer si la palabra _w_ es correcta o incorrecta. Tampoco, de ser incorrecta, conocemos la palabra candidata (de existir) a la que debería ser corregida.\n",
        "\n",
        "De esta manera, se buscará encontrar el candidato correcto (corrección) _c_ que, de todos los posibles candidatos, maximize la probabilidad de que, dada la palabra _w_, sea _c_ la corrección.\n",
        "\n",
        "Esto es:\n",
        "<center>argmax<sub>c $\\in$ candidates </sub> P(c|w)</center>\n",
        "\n",
        "Que por Bayes es equivalente a:\n",
        "<center>argmax<sub>c $\\in$ candidates </sub> P(c)P(w|c)/P(w)</center>\n",
        "\n",
        "Donde P(w) puede eliminarse al ser la misma para cada posible candidato:\n",
        "<center>argmax<sub>c $\\in$ candidates </sub> P(c)P(w|c)</center>\n",
        "\n",
        "Los partes de esta expresión son, por tanto:\n",
        "1. Mecanismo de selección: _argmax_\n",
        "Se elige el candidato que maximiza la probabilidad.\n",
        "2. Modelo de candidatos: _c $\\in$ candidates_\n",
        "Elige los candidatos a tener en cuenta.\n",
        "3. Modelo de lenguaje: _P(c)_\n",
        "La probabilidad de que _c_ apareza como palabra en un texto (probabilidad de ocurrencia)\n",
        "4. Modelo de error: _P(w|c)_\n",
        "La probabilidad de que w fuese escrita cuando realmente se quería escribir c."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnW_E06qZR48"
      },
      "outputs": [],
      "source": [
        "#Ejercicio sobre spelling corrector en NLP\n",
        "import re\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtedhMm9ZR49"
      },
      "outputs": [],
      "source": [
        "def words(text): return re.findall(r'\\w+', text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(list(filter(None, reviews_list)))\n",
        "WORDS = Counter(words(text))"
      ],
      "metadata": {
        "id": "4Y1bjx8TYwt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IfaUM1A5ZR49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93915a33-e9e2-433e-ab25-e1002e5dab8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 110320),\n",
              " ('que', 75818),\n",
              " ('la', 69958),\n",
              " ('y', 54669),\n",
              " ('en', 49071),\n",
              " ('el', 47192),\n",
              " ('a', 38985),\n",
              " ('un', 30316),\n",
              " ('una', 24828),\n",
              " ('es', 24347),\n",
              " ('los', 23787),\n",
              " ('no', 22500),\n",
              " ('se', 20925),\n",
              " ('con', 20596),\n",
              " ('por', 18558),\n",
              " ('del', 17972),\n",
              " ('su', 16074),\n",
              " ('lo', 14570),\n",
              " ('las', 13757),\n",
              " ('como', 12967),\n",
              " ('más', 12407),\n",
              " ('para', 11752),\n",
              " ('al', 11599),\n",
              " ('película', 11228),\n",
              " ('pero', 9414),\n",
              " ('o', 7125),\n",
              " ('sus', 5773),\n",
              " ('me', 5767),\n",
              " ('todo', 5631),\n",
              " ('sin', 5478),\n",
              " ('si', 5202),\n",
              " ('esta', 5065),\n",
              " ('ha', 4991),\n",
              " ('cine', 4987),\n",
              " ('le', 4804),\n",
              " ('muy', 4719),\n",
              " ('ya', 4567),\n",
              " ('nos', 4420),\n",
              " ('historia', 4289),\n",
              " ('este', 4087),\n",
              " ('ser', 4030),\n",
              " ('son', 3677),\n",
              " ('tiene', 3320),\n",
              " ('está', 3291),\n",
              " ('bien', 3251),\n",
              " ('hay', 3141),\n",
              " ('sobre', 3135),\n",
              " ('tan', 3095),\n",
              " ('aunque', 3019),\n",
              " ('uno', 2888),\n",
              " ('cuando', 2839),\n",
              " ('ni', 2835),\n",
              " ('hace', 2787),\n",
              " ('dos', 2668),\n",
              " ('ver', 2637),\n",
              " ('entre', 2632),\n",
              " ('algo', 2624),\n",
              " ('personajes', 2577),\n",
              " ('vez', 2539),\n",
              " ('poco', 2510),\n",
              " ('también', 2484),\n",
              " ('film', 2479),\n",
              " ('vida', 2458),\n",
              " ('final', 2431),\n",
              " ('puede', 2421),\n",
              " ('todos', 2411),\n",
              " ('director', 2409),\n",
              " ('mejor', 2384),\n",
              " ('parte', 2343),\n",
              " ('hasta', 2329),\n",
              " ('películas', 2286),\n",
              " ('porque', 2285),\n",
              " ('nada', 2277),\n",
              " ('eso', 2266),\n",
              " ('desde', 2220),\n",
              " ('mucho', 2210),\n",
              " ('menos', 2173),\n",
              " ('así', 2128),\n",
              " ('gran', 2125),\n",
              " ('donde', 2079),\n",
              " ('guión', 2036),\n",
              " ('ese', 2010),\n",
              " ('personaje', 1967),\n",
              " ('tanto', 1914),\n",
              " ('siempre', 1911),\n",
              " ('mundo', 1900),\n",
              " ('años', 1867),\n",
              " ('mi', 1825),\n",
              " ('cinta', 1811),\n",
              " ('otro', 1774),\n",
              " ('sólo', 1768),\n",
              " ('hacer', 1748),\n",
              " ('parece', 1699),\n",
              " ('otra', 1672),\n",
              " ('e', 1665),\n",
              " ('espectador', 1650),\n",
              " ('esa', 1644),\n",
              " ('mismo', 1612),\n",
              " ('sí', 1612),\n",
              " ('han', 1601)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "WORDS.most_common(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YbmXd-WZR49"
      },
      "outputs": [],
      "source": [
        "#Ejercicio sobre spelling corrector en NLP\n",
        "#WORDS es la frecuencia. \n",
        "#Los valores son las veces que ocurre.\n",
        "#N es el tamaño total de palabras que hay en el texto.\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_W9mFUBZR49"
      },
      "outputs": [],
      "source": [
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbYBDTnnZR49"
      },
      "outputs": [],
      "source": [
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwChUDeZZR4-"
      },
      "outputs": [],
      "source": [
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkcwZiaaZR4-"
      },
      "outputs": [],
      "source": [
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlz4ocGOZR4-"
      },
      "outputs": [],
      "source": [
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUvpw-raZR4-",
        "outputId": "2d1ed641-8ddc-4488-a35c-0498c67c761c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "390"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(edits1('pelicul'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mftdgWqzZR4-",
        "outputId": "9dd49281-5d36-43f2-f52e-762291aa5276"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162150"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(list(edits2('pelicul')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lkpmRP0SZR4-",
        "outputId": "ba4925fd-5ae9-4aba-8f0e-66545c4c429a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pelicula'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "correction('pelicul')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(edits2('pelicul'))"
      ],
      "metadata": {
        "id": "nJpX-NslY0uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_words = [\n",
        "    'pelicul',\n",
        "    'guerr',\n",
        "    'perona',\n",
        "    'malha',\n",
        "    'bueena',\n",
        "    'rwsa',\n",
        "    'entrida',\n",
        "    'cime',\n",
        "    'pelicula'\n",
        "]"
      ],
      "metadata": {
        "id": "KjQdXrVGY4FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:20}{1:20}'.format('Palabra', 'Correción'))\n",
        "\n",
        "for word in wrong_words:\n",
        "    print('{0:20}{1:20}'.format(word, correction(word)))"
      ],
      "metadata": {
        "id": "HNV96BtkY7bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7k2qVycZR4_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdEBzCRUZR4_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITY-FQE4ZR4_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}