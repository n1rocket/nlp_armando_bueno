{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_2HaKJJTUHy"
      },
      "source": [
        "# spaCy\n",
        "\n",
        "spaCy es otra librería open source en Python para NLP.\n",
        "\n",
        "La diferencia fundamental entre NLTK y spaCy es que el primero es muy cómodo para aprender e iniciarse mientras que el segundo está pensado para productizar.\n",
        "\n",
        "Gensim, otra librería, la veremos más adelante cuando estudiemos Topic Modeling y Word Embeddings.\n",
        "\n",
        "Documentación de spaCy: https://spacy.io/\n",
        "\n",
        "La filosofía de trabajo en spaCy es que si existen una serie de algoritmos que solucionan un problema, dar la solución al problema con un único. Además, su funcionamiento se basa en la construcción de pipelines.\n",
        "\n",
        "\n",
        "<img src=https://i.imgur.com/nD7ut2U.jpg>\n",
        "\n",
        "¿Qué capacidades (modelos) linguísticas nos ofrece spaCy?\n",
        "\n",
        "<img src=https://i.imgur.com/lGcL6lx.jpg>\n",
        "\n",
        "Es decir, de spaCy podremos sacar siempre que queramos tokens, pos tags, árboles de dependencia, o entidades nombradas. Incluye también modelos de word embeddings (que veremos con más detalle en sesiones posteriores)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IomNqNVLTUH1"
      },
      "source": [
        "<img src=https://spacy.io/architecture-bcdfffe5c0b9f221a2f6607f96ca0e4a.svg width=550px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DFo1vEnTUH1"
      },
      "source": [
        "## Modelos de spaCy\n",
        "\n",
        "Modelos pre-entrenados para diferentes idiomas y con diferentes corpus. Pueden ser descargados de diferentes maneras, tanto descarga directa, como con pip.\n",
        "\n",
        "Link: https://spacy.io/usage/models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-CowJoZUN6Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy download es_core_news_sm\n",
        "!pip install -U spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "-71CXhu5DTcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **spacy**"
      ],
      "metadata": {
        "id": "9dbmZtKsoDAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spacy es una librería de procesamiento del lenguaje natural, robusta, rápida, fácil de instalar y utilizar e integrable con otras librerías de NLP y de deep learning\n",
        "\n",
        "Tiene modelos entrenados en varios idiomas y permite realizar las típicas tareas de segmentación por oraciones, tokenizanción, análisis morfológico, extracción de entidades y análisis de opinión.\n",
        "\n",
        "Una vez instalados los modelos, podemos importarlos fácilmente:\n",
        "\n"
      ],
      "metadata": {
        "id": "dD-RWLjHoJ8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import es_core_news_sm\n",
        "import en_core_web_sm\n",
        "\n",
        "# Modelo \"pequeño\" entrenado con noticias en castellano\n",
        "# https://spacy.io/models/es\n",
        "nlp_es = es_core_news_sm.load()\n",
        "\n",
        "# Modelo \"pequeño\" entrenado con página\n",
        "# https://spacy.io/models/en\n",
        "nlp_en = en_core_web_sm.load()"
      ],
      "metadata": {
        "id": "zz38LNNYR71J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd2c402-1e52-480d-d894-5b05079802bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/util.py:877: UserWarning: [W095] Model 'es_core_news_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline del modelo por defecto\n",
        "nlp_es.pipeline"
      ],
      "metadata": {
        "id": "LXM9AV6yR_FU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690ca420-e671-49e9-a53f-5089333b1bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f24ac97c100>),\n",
              " ('morphologizer',\n",
              "  <spacy.pipeline.morphologizer.Morphologizer at 0x7f24ac8703a0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f24ac824270>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f24ac8024c0>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.es.lemmatizer.SpanishLemmatizer at 0x7f24ac80d440>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f24ac8243c0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_en.pipeline"
      ],
      "metadata": {
        "id": "_D3jzz2rSCWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80eafb4a-61f9-40fd-f0b5-1ad28da3f271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f24ac42efa0>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f24ac42e700>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f24ac9757b0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f24ac3c09c0>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f24ac418c80>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f24ac9756d0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvsOJmI5TUH5"
      },
      "source": [
        "Pipelines en spaCy:\n",
        "https://spacy.io/usage/processing-pipelines\n",
        "\n",
        "<img src=https://d33wubrfki0l68.cloudfront.net/16b2ccafeefd6d547171afa23f9ac62f159e353d/48b91/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg width=700px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwvh9uCATUH5"
      },
      "outputs": [],
      "source": [
        "text = 'Mi nombre es Cristina y vivo en Madrid. Hoy es martes 20 de Febrero'\n",
        "doc = nlp_es(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmkOMC-KTUH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c197bda4-2265-4afb-f6ff-87db169c1b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mi nombre es Cristina y vivo en Madrid. Hoy es martes 20 de Febrero\n"
          ]
        }
      ],
      "source": [
        "print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fKMvQfQTUH6"
      },
      "source": [
        "# Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtGthRPJTUH6"
      },
      "source": [
        "## Frases"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en el doc generado vamos a ver las frases que tienen\n",
        "for idx, sent in enumerate(doc.sents):\n",
        "    print('Frase {0:5}{1:5}'.format(str(idx), sent.text))"
      ],
      "metadata": {
        "id": "zUbj3DnVSJW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37931e4c-f9c7-450a-83e2-66359211cdd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 0    Mi nombre es Cristina y vivo en Madrid.\n",
            "Frase 1    Hoy es martes 20 de Febrero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKRorfHjTUH6"
      },
      "source": [
        "## Tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#queremos ver cuales son los tokens, cuales son las palabras que hay. tambi´ne podemos verlos automaticamente, iterame sobre doc\n",
        "for idx, token in enumerate(doc):\n",
        "    print('Token {0:5}{1:5}'.format(str(idx), token.text))"
      ],
      "metadata": {
        "id": "R8QFYZziSMOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2d465d-1e5f-4659-ea44-261cca730eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 0    Mi   \n",
            "Token 1    nombre\n",
            "Token 2    es   \n",
            "Token 3    Cristina\n",
            "Token 4    y    \n",
            "Token 5    vivo \n",
            "Token 6    en   \n",
            "Token 7    Madrid\n",
            "Token 8    .    \n",
            "Token 9    Hoy  \n",
            "Token 10   es   \n",
            "Token 11   martes\n",
            "Token 12   20   \n",
            "Token 13   de   \n",
            "Token 14   Febrero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# un análisis mas detallado sobre los tokens, por ejemplo si es alfanumerico\n",
        "\n",
        "\n",
        "print('{0:10}{1:10}{2:5}'.format('Token', 'Shape', 'is_alpha'))\n",
        "for token in doc:\n",
        "    print('{0:10}{1:10}{2:5}'.format(token.text, token.shape_, str(token.is_alpha)))"
      ],
      "metadata": {
        "id": "OKiOdyoMSRHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0944577e-6dbf-4f21-b607-b597bfa7a17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Shape     is_alpha\n",
            "Mi        Xx        True \n",
            "nombre    xxxx      True \n",
            "es        xx        True \n",
            "Cristina  Xxxxx     True \n",
            "y         x         True \n",
            "vivo      xxxx      True \n",
            "en        xx        True \n",
            "Madrid    Xxxxx     True \n",
            ".         .         False\n",
            "Hoy       Xxx       True \n",
            "es        xx        True \n",
            "martes    xxxx      True \n",
            "20        dd        False\n",
            "de        xx        True \n",
            "Febrero   Xxxxx     True \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnFjB1N-TUH7"
      },
      "source": [
        "# Normalización de texto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar stop words\n",
        "from spacy.lang.es.stop_words import STOP_WORDS\n",
        "\n",
        "print(list(STOP_WORDS)[:20])"
      ],
      "metadata": {
        "id": "czJ76npSSYar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e44f1d-875b-49b6-817f-31b73e34ce8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fuera', 'pocos', 'usan', 'eras', 'ambos', 'mencionó', 'usas', 'mis', 'algún', 'dio', 'ello', 'yo', 'buen', 'allí', 'muchas', 'tuvo', 'estará', 'podrán', 'quizas', 'hecho']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(STOP_WORDS))"
      ],
      "metadata": {
        "id": "ndFBu96mSk_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad378d8a-39f6-453a-83ad-1a42b7a907f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "521"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_1 = 'Soy una frase de ejemplo de la cual vamos a eliminar los stopwords'\n",
        "[word for word in ex_text_1.lower().split() if word not in STOP_WORDS]"
      ],
      "metadata": {
        "id": "utesHnuxSlGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae4f936-d50c-4203-e237-5b849f8e65c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['frase', 'ejemplo', 'eliminar', 'stopwords']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_aszsjkTUH7"
      },
      "source": [
        "Debate: ¿Pensáis que, en general, se deben filtrar los stopwords?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_2 = 'No me gusta esta canción'\n",
        "[word for word in ex_text_2.lower().split() if word not in STOP_WORDS]"
      ],
      "metadata": {
        "id": "46EDFjA0Sr4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d266f82-94ab-4789-c455-e7bbad7d54d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gusta', 'canción']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "if 'no' in STOP_WORDS:\n",
        "  print ('Es stopword en English')"
      ],
      "metadata": {
        "id": "GjGfF1aVSuxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1007c37-f464-44d0-f630-543b3c5bb18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Es stopword en English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkbNntIATUH7"
      },
      "source": [
        "# Part of Speech tagging\n",
        "\n",
        "El PoS Tagging es una técnica **fundamental** en NLP que consiste en etiquetar cada palabra de un documento en su correspondiente categría gramatical.\n",
        "\n",
        "<img src=https://blog.aaronccwong.com/assets/images/bigram-hmm/pos-title.jpg width=650px>\n",
        "\n",
        "¿Utilidad? Muchísima:\n",
        "\n",
        "- Posibilidad de encontrar los adjetivos / sustantivos /adverbios más comunes\n",
        "- _Ayuda_ a Lemmatizers al desambiguar entre palabras\n",
        "- Grafos en los que los nodos son entidades y verbos. Posibilidad de analizar relaciones entre entidades -> Pintar ejemplo\n",
        "- Posibles features (la distribución de categorías no siempre es homogénea en función del contexto)\n",
        "\n",
        "Podríamos hacer un algoritmo que mirara verbos entre otras entidades, como nombres o adjetivos, y que fuera el verbo quien decidiera que relación tienen esas entidades. Eso se suele hacer para crear bases de datos de grafos, donde cada nodo es una entidad, y entre entidades hay relaciones.\n",
        "\n",
        "Veamos algún ejemplo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5EWLOSITUH7"
      },
      "source": [
        "Atributos (https://spacy.io/api/token#attributes):\n",
        "- pos_: tipo de palabra (sustantivo, verbo, adjetivo, etc)\n",
        "- tag_: tipo de palabra especificando más atributos\n",
        "- dep_: relación de dependencia sintáctica\n",
        "\n",
        "Explicación de los términos:\n",
        "https://github.com/explosion/spaCy/blob/master/spacy/glossary.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgfCQfIDTUH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1ad8ef-600e-4f28-b991-edd7fab896d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mi nombre es Cristina y vivo en Madrid. Hoy es martes 20 de Febrero"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCEDEMOS AL TOKEN.POS_ Para saber la etiqueta que tienen\n",
        "\n",
        "print('{0:10}{1:10}'.format('Token', 'pos'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}'.format(token.text, token.pos_))"
      ],
      "metadata": {
        "id": "XzzzW4DmS26q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a624ca-acdc-4f8e-8465-5fecaeadf219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     pos       \n",
            "Mi        DET       \n",
            "nombre    NOUN      \n",
            "es        AUX       \n",
            "Cristina  PROPN     \n",
            "y         CCONJ     \n",
            "vivo      VERB      \n",
            "en        ADP       \n",
            "Madrid    PROPN     \n",
            ".         PUNCT     \n",
            "Hoy       ADV       \n",
            "es        AUX       \n",
            "martes    NOUN      \n",
            "20        NUM       \n",
            "de        ADP       \n",
            "Febrero   NOUN      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lo mismo la parte de los tags\n",
        "print('{0:10}{1:10}'.format('Token', 'tag'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}'.format(token.text, token.tag_))"
      ],
      "metadata": {
        "id": "g4hbDQVDS29E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7570b3e6-b51f-4d98-dc1d-09aa352efede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     tag       \n",
            "Mi        DET       \n",
            "nombre    NOUN      \n",
            "es        AUX       \n",
            "Cristina  PROPN     \n",
            "y         CCONJ     \n",
            "vivo      VERB      \n",
            "en        ADP       \n",
            "Madrid    PROPN     \n",
            ".         PUNCT     \n",
            "Hoy       ADV       \n",
            "es        AUX       \n",
            "martes    NOUN      \n",
            "20        NUM       \n",
            "de        ADP       \n",
            "Febrero   NOUN      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}{2:10}'.format('Token', 'dep', 'Meaning'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.dep_, str(spacy.explain(token.dep_))))"
      ],
      "metadata": {
        "id": "iu_KVVvRS2_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9314f824-e141-4d53-b461-be2b66ce15fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     dep       Meaning   \n",
            "Mi        det       determiner\n",
            "nombre    nsubj     nominal subject\n",
            "es        cop       copula    \n",
            "Cristina  ROOT      root      \n",
            "y         cc        coordinating conjunction\n",
            "vivo      conj      conjunct  \n",
            "en        case      case marking\n",
            "Madrid    nmod      modifier of nominal\n",
            ".         punct     punctuation\n",
            "Hoy       advmod    adverbial modifier\n",
            "es        fixed     fixed multiword expression\n",
            "martes    ROOT      root      \n",
            "20        compound  compound  \n",
            "de        case      case marking\n",
            "Febrero   compound  compound  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juPA60ohTUH8"
      },
      "source": [
        "# Dependencia sintáctica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQeqFTelTUH8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "5ea2e78a-0c37-4fa1-9857-fc924040b7f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"aa7ebf0d7d1b4b27baf2a5f120e841d0-0\" class=\"displacy\" width=\"1450\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mi</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">nombre</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">es</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">Cristina</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">y</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">vivo</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">en</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Madrid.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">Hoy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">es</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">martes</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">20</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">de</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">Febrero</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,102.0 140.0,102.0 140.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,52.0 345.0,52.0 345.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-2\" stroke-width=\"2px\" d=\"M270,152.0 C270,102.0 340.0,102.0 340.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M270,154.0 L262,142.0 278,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-3\" stroke-width=\"2px\" d=\"M470,152.0 C470,102.0 540.0,102.0 540.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M470,154.0 L462,142.0 478,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-4\" stroke-width=\"2px\" d=\"M370,152.0 C370,52.0 545.0,52.0 545.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M545.0,154.0 L553.0,142.0 537.0,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-5\" stroke-width=\"2px\" d=\"M670,152.0 C670,102.0 740.0,102.0 740.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-6\" stroke-width=\"2px\" d=\"M370,152.0 C370,2.0 750.0,2.0 750.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,154.0 L758.0,142.0 742.0,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-7\" stroke-width=\"2px\" d=\"M870,152.0 C870,52.0 1045.0,52.0 1045.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M870,154.0 L862,142.0 878,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-8\" stroke-width=\"2px\" d=\"M870,152.0 C870,102.0 940.0,102.0 940.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">fixed</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M940.0,154.0 L948.0,142.0 932.0,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-9\" stroke-width=\"2px\" d=\"M1070,152.0 C1070,102.0 1140.0,102.0 1140.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1140.0,154.0 L1148.0,142.0 1132.0,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-10\" stroke-width=\"2px\" d=\"M1270,152.0 C1270,102.0 1340.0,102.0 1340.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270,154.0 L1262,142.0 1278,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-11\" stroke-width=\"2px\" d=\"M1070,152.0 C1070,52.0 1345.0,52.0 1345.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa7ebf0d7d1b4b27baf2a5f120e841d0-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1345.0,154.0 L1353.0,142.0 1337.0,142.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance':100})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOGzhUMOTUH8"
      },
      "source": [
        "# Reconocimiento de entidades nombradas (NER)\n",
        "\n",
        "El reconocimiento de entidades nombradas (Named Entity Recognition, NER, por sus siglas en inglés) trata de detectar posibles entidades nombradas y, posteriormente, clasificarlas entre un conjunto de categorías predefinidas.\n",
        "\n",
        "Ejemplos de entidades nombradas: nombres de personas, lugares, cantidades, empresas...\n",
        "\n",
        "Pero, ¿qué es exactamente una _entidad nombrada_? Según definió Saul Kripke * (filósofo y lógico) son - o deberían ser - todas aquellas entidades para las cuales existe uno - o más de uno - designador rígido. Es decir, dicha palabra / expresión se refiere a la misma cosa / entidad con independencia del contexto.\n",
        "\n",
        "<img src=https://hyscore.io/wp-content/uploads/2019/03/illustration_named_entity_recognition-1024x486-1.jpg width=700px>\n",
        "\n",
        "El rendimiento de los NER varía mucho en función del idioma en el que han sido entrenados. El rendimiento que se comienza a obtener (debido principalmente al uso de modelos de embeddings contextuales) supera al de un ser humano.\n",
        "\n",
        "Un enlace intersante: https://primer.ai/blog/a-new-state-of-the-art-for-named-entity-recognition/\n",
        "\n",
        "* _El nombrar y la necesidad_ (Saul Kripke), 1980"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ner_1 = nlp_es('Jim compró 300 acciones de Acme Corp. en 2006')\n",
        "displacy.render(doc_ner_1, style='ent', jupyter=True, options={'distance':100})"
      ],
      "metadata": {
        "id": "UpaQZoHZTEOC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "38c003a7-cb66-47b1-a218-d53c5d5fd50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Jim compró 300 acciones de \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Acme Corp\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ". en 2006</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ner_2 = nlp_en('Peter bought 300 shares of Acme Corp. in 2006')\n",
        "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
      ],
      "metadata": {
        "id": "yn9BADHnTEZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fa2efe42-6431-4159-9e2b-7d6fc8fd9d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Peter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " bought \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    300\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " shares of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Acme Corp.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2006\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ner_2 = nlp_en('I heard that Paris Hilton stayed at the Hilton in Paris')\n",
        "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
      ],
      "metadata": {
        "id": "JEAVqlPfTEdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e7cb47c9-1bd5-435e-8fa9-ed5590799631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I heard that \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paris Hilton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " stayed at the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hilton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paris\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
        "for entity in doc_ner_1.ents:\n",
        "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
      ],
      "metadata": {
        "id": "pIYbWOeyTNBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d00de7b-7ba5-429f-ba37-c2a305714f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Entity Label\n",
            "Acme Corp PER       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
        "for entity in doc_ner_2.ents:\n",
        "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
      ],
      "metadata": {
        "id": "9X3SDk18TND5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b9f2c0-e676-4213-86c3-f86f0a99c2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Entity Label\n",
            "Paris HiltonORG       \n",
            "Hilton    GPE       \n",
            "Paris     GPE       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GR81bkOTTNHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EhiGqkKTUH9"
      },
      "source": [
        "# Lemmatization\n",
        "\n",
        "Técnica de normalización de textos que busca reducir las palabras a su raíz (lemma).\n",
        "\n",
        "Muy utilizado para reducir la cardinalidad del vocabulario asociando para diferentes formas flexionadas un único token ('entreno', 'entrenarás', 'entrenaría' -> 'entrenar').\n",
        "\n",
        "Aunque muy utilizados en motores de búsqueda "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
      ],
      "metadata": {
        "id": "7ViLaBA0TVUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f77a4f-a03f-4fde-9b6f-5cbc5a64565a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Lemma     PoS Tag   \n",
            "Mi        mi        DET       \n",
            "nombre    nombre    NOUN      \n",
            "es        ser       AUX       \n",
            "Cristina  Cristina  PROPN     \n",
            "y         y         CCONJ     \n",
            "vivo      vivir     VERB      \n",
            "en        en        ADP       \n",
            "Madrid    Madrid    PROPN     \n",
            ".         .         PUNCT     \n",
            "Hoy       hoy       ADV       \n",
            "es        ser       AUX       \n",
            "martes    martes    NOUN      \n",
            "20        20        NUM       \n",
            "de        de        ADP       \n",
            "Febrero   febrero   NOUN      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = 'comer comiendo comieron comedor comeré comerá comerás'\n",
        "text_3 = 'comerás'\n",
        "doc_2 = nlp_es(text_2)\n",
        "doc_3 = nlp_es(text_3)\n",
        "\n",
        "\n",
        "print('Text 2')\n",
        "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
        "for idx, token in enumerate(doc_2):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))\n",
        "\n",
        "print('\\nText 3')\n",
        "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
        "for idx, token in enumerate(doc_3):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
      ],
      "metadata": {
        "id": "N66xn0jtTZUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf28e4f9-a415-493c-d559-8870c0746097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 2\n",
            "Token     Lemma     PoS Tag   \n",
            "comer     comer     VERB      \n",
            "comiendo  comer     VERB      \n",
            "comieron  comer     VERB      \n",
            "comedor   comedor   NOUN      \n",
            "comeré    comeré    ADJ       \n",
            "comerá    comer     VERB      \n",
            "comerás   comerás   ADP       \n",
            "\n",
            "Text 3\n",
            "Token     Lemma     PoS Tag   \n",
            "comerás   comerás   ADP       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4DSGTaKTUH9"
      },
      "source": [
        "# Lemmatization vs Stemming\n",
        "\n",
        "Ambas tienen como objetivo reducir las palabras a su raíz léxica.\n",
        "\n",
        "- **Lemmatization**:\n",
        "\n",
        "    Tiene en consideración el análisis morfológico de las palabras. Son necesarios diccionarios completos de formas flexionadas y raíces (lemmas).\n",
        "    \n",
        "    A veces es necesario desambiguar. P. ej.: \"planta\" (planta vs plantar)\n",
        "\n",
        "<img src=https://blog.bitext.com/hs-fs/hubfs/lemma_v2.png width=500px>\n",
        "\n",
        "- **Stemming**:\n",
        "    \n",
        "    Algoritmos que mediante heurísticos / reglas tratan de reducir las palabras a una posible raíz (stem) mediante la eliminación de algunos prefijos y sufijos. Más sencillo que un lemmatizer\n",
        "    \n",
        "    No hay garantía de que el resultado sea una palabra real.\n",
        "    \n",
        "    El algoritmo más utilizado en Inglés es el de Porter que consiste en 5 fases de reducción de la palabra aplicadas de manera secuencial.\n",
        "    <img src=https://blog.bitext.com/hs-fs/hubfs/stemming_v2.png width=250px>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "81x3r5kQ5n1J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88SgI_h-SflN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Th9-DvfSfoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET5fH6OyTUH-"
      },
      "source": [
        "# Similitud\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy permite calcular la similitud semántica entre cualquier par de objetos de tipo Doc, Span o Token.\n",
        "\n",
        "Ojo, La similitud semántica es un concepto algo subjetivo, pero en este caso se puede entender como la probabilidad de que dos palabras aparezcan en los mismos contextos."
      ],
      "metadata": {
        "id": "LM2-fsNJW3V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U spacy && python -m spacy download es\n",
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_md\n"
      ],
      "metadata": {
        "id": "yusN6xB2Dazg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# cargamos el modelo entrenado en español\n",
        "nlp_es_md = spacy.load(\"es_core_news_md\")"
      ],
      "metadata": {
        "id": "3HyDQCj6XOe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cUYSeKZLTUH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4171ada5-cf20-482b-d63d-e529c0bf2071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between word 1 and word 2: 0.743638\n",
            "Similarity between word 1 and word 3: 0.382572\n",
            "Similarity between word 2 and word 3: 0.442991\n"
          ]
        }
      ],
      "source": [
        "word_1 = nlp_es_md('verde')\n",
        "word_2 = nlp_es_md('azul')\n",
        "word_3 = nlp_es_md('mariposa')\n",
        "\n",
        "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 2, word_1.similarity(word_2)))\n",
        "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 3, word_1.similarity(word_3)))\n",
        "print('Similarity between word {} and word {}: {:0.6f}'.format(2, 3, word_2.similarity(word_3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v4s5tguTUH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d428ac-f12e-4cbc-f0b0-f29501d7b32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between sent 1 and sent 2: 0.967595\n",
            "Similarity between sent 1 and sent 3: 0.651385\n",
            "Similarity between sent 2 and sent 3: 0.653034\n"
          ]
        }
      ],
      "source": [
        "sent_1 = nlp_es_md('me gusta el color verde')\n",
        "sent_2 = nlp_es_md('me gusta el azul')\n",
        "sent_3 = nlp_es_md('me gusta la mariposa')\n",
        "\n",
        "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 2, sent_1.similarity(sent_2)))\n",
        "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 3, sent_1.similarity(sent_3)))\n",
        "print('Similarity between sent {} and sent {}: {:0.6f}'.format(2, 3, sent_2.similarity(sent_3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wtIJ5aeTUH_"
      },
      "source": [
        "# El Universo de spaCy\n",
        "\n",
        "Diferentes recursos (paquetes, plugins, extensiones, etc) desarrollados por o para spaCy.\n",
        "\n",
        "https://spacy.io/universe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB6rZgJ2TUH_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGelgbgMTUH_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}