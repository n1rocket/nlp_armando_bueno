{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! unzip merged_clean.txt.zip"
      ],
      "metadata": {
        "id": "2x9WEUCSfRGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcQYN08XyilW"
      },
      "source": [
        "https://huggingface.co/datasets/merve/folk-mythology-tales/tree/main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install hmmlearn"
      ],
      "metadata": {
        "id": "OrFMAoaqfUUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head merged_clean.txt"
      ],
      "metadata": {
        "id": "BV7iET3BfXgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67pzcYDr38D9"
      },
      "source": [
        "# Hidden Markov Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iATIPKrkwnk1"
      },
      "outputs": [],
      "source": [
        "import sys, json, codecs, pickle, argparse\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from hmmlearn import hmm\n",
        "from nltk import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebq9VbohwvWi"
      },
      "outputs": [],
      "source": [
        "file = open(\"./merged_clean.txt\", 'r', encoding='utf-8').read()\n",
        "sentences = file.split(\"\\n\")\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "for index, sentence in enumerate(sentences):\n",
        "  if sentence == \"\":\n",
        "      del sentences[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reXU0xm2wbD3"
      },
      "outputs": [],
      "source": [
        "lines = [line.split() for line in sentences]\n",
        "\n",
        "for line_index, line in enumerate(lines):\n",
        "  for word_index, word in enumerate(line):\n",
        "    lines[line_index][word_index] = word.translate(table)\n",
        "\n",
        "words = [word.lower() for line in lines for word in line]\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "for index, word in enumerate(words):\n",
        "    words[index] = word.translate(table)\n",
        "\n",
        "alphabet = set(words)\n",
        "le = LabelEncoder()\n",
        "le.fit(list(alphabet))\n",
        "\n",
        "seq = le.transform(words)\n",
        "features = np.fromiter(seq, np.int64)\n",
        "features = features.reshape(-1, 1)\n",
        "# features = np.atleast_2d(features).T\n",
        "fd = FreqDist(seq)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(alphabet))\n",
        "print(words[:10])\n",
        "print(seq[:10])\n",
        "print(features[:10])\n",
        "print(fd.get(0))"
      ],
      "metadata": {
        "id": "rOdv1pYTfae0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNoht_gpwe12"
      },
      "outputs": [],
      "source": [
        "model = hmm.CategoricalHMM(n_components=3, init_params=\"ste\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines[:2])\n",
        "print(features[:2])"
      ],
      "metadata": {
        "id": "5ggaY-xNfenQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FBKxbdNyB8f"
      },
      "outputs": [],
      "source": [
        "model = model.fit(features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbols, _states = model.sample(20, random_state=42)\n",
        "output = le.inverse_transform(np.squeeze(symbols))\n",
        "for word in output:\n",
        "        print(word, end=\" \")"
      ],
      "metadata": {
        "id": "7b7co5MTfhGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69_SHtgT_Inv"
      },
      "source": [
        "# GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --force-reinstall transformers[tf-cpu] tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "Dm8tM8Ajfkfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    GPT2Tokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TextDataset,\n",
        "    GPT2LMHeadModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    pipeline)"
      ],
      "metadata": {
        "id": "sc-99eZpfm5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmz50YlDN8SF"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qyPQcqdN-qI"
      },
      "outputs": [],
      "source": [
        "print('vocabulary size: %d, max squence length: %d' % (tokenizer.vocab_size, tokenizer.model_max_length))\n",
        "print('tokenize sequence \"Once upon a time in a little village\":', tokenizer('Once upon a time in a little village'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w92Lslq__XcI"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVvE7YubOBvA"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"merged_clean.txt\",\n",
        "    block_size=128)\n",
        "     \n",
        "test_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"merged_clean.txt\",\n",
        "    block_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQt3Qd3cOEfL"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(train_dataset[5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvPU8TlhOGrE"
      },
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVAWsMxwOI0x"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = 'data/out', # the output directory for the model predictions and checkpoints\n",
        "    overwrite_output_dir = True, # overwrite the content of the output directory\n",
        "    per_device_train_batch_size = 4, # the batch size for training\n",
        "    per_device_eval_batch_size = 4, # the batch size for evaluation\n",
        "    learning_rate = 5e-5, # defaults to 5e-5\n",
        "    num_train_epochs = 1, # total number of training epochs to perform\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY44TOgcg8Zr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7sjM-aCOMb7"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpMs-KAxuzRX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(3600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVmIdWcKOPfv"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_88c5r_OSHC"
      },
      "outputs": [],
      "source": [
        "generator = pipeline('text-generation', tokenizer='gpt2', model='data/out')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj8oaToyOUmU"
      },
      "outputs": [],
      "source": [
        "print(generator('There is a building', max_length=500)[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZPA6dPtOXdQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepESP/gpt2-spanish\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"DeepESP/gpt2-spanish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rd43triOaaE"
      },
      "outputs": [],
      "source": [
        "generator = pipeline('text-generation', tokenizer='DeepESP/gpt2-spanish', model='DeepESP/gpt2-spanish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shx8oGltOeXA"
      },
      "outputs": [],
      "source": [
        "print(generator('Había una vez', max_length=100)[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NioVolm5zG5I"
      },
      "outputs": [],
      "source": [
        "generator = pipeline('sentiment-analysis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8fwXj06zcOe"
      },
      "outputs": [],
      "source": [
        "print(generator('this is very good'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}