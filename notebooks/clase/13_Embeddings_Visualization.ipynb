{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_VKyJyzMNrb"
      },
      "source": [
        "# Importamos las librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiMu9LvsMNrd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.word2vec import LineSentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjkSzQerMNrd"
      },
      "source": [
        "# Cargamos un modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_sg = Word2Vec.load('./w2v_model.pkl')"
      ],
      "metadata": {
        "id": "VicQ7HHcRzuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_sg.wv.most_similar('homer')"
      ],
      "metadata": {
        "id": "Yzim7nRgNSaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuenCDpvMNrf"
      },
      "source": [
        "# Creamos _clusters_ de palabras con las más similares a unas dadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vrXk7mrMNrf"
      },
      "outputs": [],
      "source": [
        "keys = ['homer','pregnant','university','marge']\n",
        "\n",
        "embedding_clusters = []\n",
        "word_clusters = []\n",
        "for word in keys:\n",
        "    embeddings = []\n",
        "    words = []\n",
        "    for similar_word, _ in w2v_sg.wv.most_similar(word, topn=10):\n",
        "        words.append(similar_word)\n",
        "        embeddings.append(w2v_sg.wv[similar_word])\n",
        "    embedding_clusters.append(embeddings)\n",
        "    word_clusters.append(words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_clusters)"
      ],
      "metadata": {
        "id": "WtaXfIqbNWHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3lKe6cvMNrg"
      },
      "source": [
        "# Reducimos dimensionalidad a 2D para poder representar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxmbJYQKMNrg"
      },
      "outputs": [],
      "source": [
        "tsne_model_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g4CbYaVMNrh"
      },
      "outputs": [],
      "source": [
        "embedding_clusters = np.array(embedding_clusters)\n",
        "n, m, k = embedding_clusters.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_2d = np.array(tsne_model_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)"
      ],
      "metadata": {
        "id": "7-gSBQwyNZKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU6bV7VdMNri"
      },
      "source": [
        "# Visualización"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def tsne_plot_similar_words(labels, embedding_clusters, word_clusters, a=0.7):\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
        "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
        "        x = embeddings[:,0]\n",
        "        y = embeddings[:,1]\n",
        "        plt.scatter(x, y, c=[color], alpha=a, label=label)\n",
        "        for i, word in enumerate(words):\n",
        "            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2), \n",
        "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.title('Representación en 2D de los embeddings de algunos clusters de palabras')\n",
        "    # plt.savefig(\"f/г.png\", format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "tsne_plot_similar_words(keys, embeddings_2d, word_clusters)"
      ],
      "metadata": {
        "id": "dYOmWAYRNdKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A908OjDGMNrj"
      },
      "source": [
        "## Embedding projector online\n",
        "\n",
        "Permite cargar un fichero TSV con los word embeddings pre-calculados y representarlos en una representación interactiva en 3D. \n",
        "\n",
        "La reducción de dimensionalidad puede realizarse mediante UMAP, t-SNE o PCA.\n",
        "\n",
        "Además, permite cargar los vectores con metadata como, por ejemplo, variables categóricas, que permitirán visualizar los topics / clusters en el espacio de 3D.\n",
        "\n",
        "https://projector.tensorflow.org\n",
        "\n",
        "<img src=https://i.ytimg.com/vi/y2rEqxzqOkM/maxresdefault.jpg>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK4MmxXOMNrj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}