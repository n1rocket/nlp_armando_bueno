{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-eDTzIVqzy-"
      },
      "source": [
        "# Librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "8ISk2ZqWEpFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRKyJi7LwT44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmDh8WReqzzA"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxCVAdjMqzzB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import gensim\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "\n",
        "\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# feed the LDA model into the pyLDAvis instance\n",
        "#lda_viz = gensimvis.prepare(ldamodel, corpus, dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3CAJYXJqzzC"
      },
      "outputs": [],
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "# feed the LDA model into the pyLDAvis instance\n",
        "#lda_viz = gensimvis.prepare(ldamodel, corpus, dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMAb-m2cqzzC"
      },
      "source": [
        "# Ejemplo con Reviews de Asistentes Virtuales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DobnURL2qzzD"
      },
      "source": [
        "# Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZxxLJr1AEzrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnIoQe02qzzE"
      },
      "source": [
        "# Preprocesado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0nzDPtCqzzE"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(token)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZxo9taFE6_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzfEfAQdqzzF"
      },
      "source": [
        "## Diccionario id - palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2QUuEb6qzzF"
      },
      "outputs": [],
      "source": [
        "dictionary = Dictionary(processed_texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8N3XAEnZE_0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1g8b-biqzzG"
      },
      "source": [
        "## Matriz documento-palabra"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M35L1_F3FCrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZfoD3gwqzzG"
      },
      "source": [
        "## Entrenamos el modelo (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVaLimCyFFPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XD8lA-eqzzH"
      },
      "source": [
        "## Perplexity y Coherence"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8Hd1KyLFI0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf7wwGK-qzzH"
      },
      "source": [
        "## Número óptimo de topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seGAQLXVqzzH"
      },
      "outputs": [],
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        \n",
        "        # Build LDA model\n",
        "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                                id2word=dictionary,\n",
        "                                                num_topics=num_topics)\n",
        "        \n",
        "        # Create a list of LDA models\n",
        "        model_list.append(model)\n",
        "        \n",
        "        # Compute the Coherence for each model\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsrHXPpNFNCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga2BcOddqzzI"
      },
      "source": [
        "# Topic dominante por texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amJIhOc9qzzI"
      },
      "outputs": [],
      "source": [
        "def format_topics_sentences(ldamodel, corpus, texts):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ludz8Go0FPOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCgyuFsSqzzI"
      },
      "source": [
        "# Documento más representativo por topic"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKknNTMAFRUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHU6qjPGqzzI"
      },
      "source": [
        "# Distribución de topics en el corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vmBq7LCQFTTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45dEHxzvqzzI"
      },
      "source": [
        "# Ejemplo con el dataset 20 newsgroup\n",
        "\n",
        "Dataset muy utilizado en NLP para entrenamiento y validación de modelos de clasificación, clustering y topic modeling. Contiene miles de artículos sobre 20 temas distintos divididos en entrenamiento y test.\n",
        "\n",
        "Algunos temas están muy  relacionados entre sí mientras que otros son muy distintos.\n",
        "\n",
        "http://qwone.com/~jason/20Newsgroups/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "\n",
        "def twenty_newsgroup_to_csv():\n",
        "    newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    df = pd.DataFrame([newsgroups_train.data, newsgroups_train.target.tolist()]).T\n",
        "    df.columns = ['text', 'target']\n",
        "\n",
        "    targets = pd.DataFrame( newsgroups_train.target_names)\n",
        "    targets.columns=['title']\n",
        "\n",
        "    out = pd.merge(df, targets, left_on='target', right_index=True)\n",
        "    out['date'] = pd.to_datetime('now')\n",
        "    out.to_csv('20_newsgroup.csv')\n",
        "    \n",
        "twenty_newsgroup_to_csv()"
      ],
      "metadata": {
        "id": "qY0nhtSBf0uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3q29MQpFZWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPftI2d_qzzJ"
      },
      "source": [
        "## Diccionario id-palabra y matrix documento-término"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ua8b6VgRFaOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxPlT0uZqzzJ"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WslL0H9ZFbd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7M4Oyi62FeiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización\n",
        "\n"
      ],
      "metadata": {
        "id": "WdZ6ZUqWFgpx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7VFxGVEFlqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N99m-uZhqzzK"
      },
      "source": [
        "## Topic dominante por documento"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ZgMzeUVFnQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htFPst4QqzzK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}